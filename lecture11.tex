\documentclass[nobib]{tufte-handout}

\title{Föreläsning 11: Probabilistiska metoden $\cdot$ 1MA020}

\author[Vilhelm Agdur]{Vilhelm Agdur\thanks{\href{mailto:vilhelm.agdur@math.uu.se}{\nolinkurl{vilhelm.agdur@math.uu.se}}}}

%\date{20 februari 2023}


%\geometry{showframe} % display margins for debugging page layout

\usepackage{graphicx} % allow embedded images
  \setkeys{Gin}{width=\linewidth,totalheight=\textheight,keepaspectratio}
  \graphicspath{{graphics/}} % set of paths to search for images
\usepackage{amsmath}  % extended mathematics
\usepackage{booktabs} % book-quality tables
\usepackage{units}    % non-stacked fractions and better unit spacing
\usepackage{multicol} % multiple column layout facilities
\usepackage{lipsum}   % filler text
\usepackage{fancyvrb} % extended verbatim environments
  \fvset{fontsize=\normalsize}% default font size for fancy-verbatim environments

\usepackage{color,soul} % Highlights for text

% Standardize command font styles and environments
\newcommand{\doccmd}[1]{\texttt{\textbackslash#1}}% command name -- adds backslash automatically
\newcommand{\docopt}[1]{\ensuremath{\langle}\textrm{\textit{#1}}\ensuremath{\rangle}}% optional command argument
\newcommand{\docarg}[1]{\textrm{\textit{#1}}}% (required) command argument
\newcommand{\docenv}[1]{\textsf{#1}}% environment name
\newcommand{\docpkg}[1]{\texttt{#1}}% package name
\newcommand{\doccls}[1]{\texttt{#1}}% document class name
\newcommand{\docclsopt}[1]{\texttt{#1}}% document class option name
\newenvironment{docspec}{\begin{quote}\noindent}{\end{quote}}% command specification environment

\include{mathcommands.extratex}

\begin{document}

\definecolor{darkgreen}{rgb}{0.0627, 0.4588, 0.1451}

\maketitle% this prints the handout title, author, and date

\begin{abstract}
\noindent
I denna föreläsning ger vi fler tillämpningar av probabilistiska metoden på olika problem, praktiska och från andra delar av matematiken. Många men inte alla kommer handla om grafer.
\end{abstract}

\section{\texttt{min-bisection}-problemet}

Antag att vi har en grupp personer på en konferens, och vi vill dela upp dem i två lika stora grupper i olika rum. Vi vill att så många som möjligt som känner varandra skall få vara i samma rum -- ekvivalent vill vi alltså minimera mängden vänskapsband mellan rummen.\sidenote[][]{
  Ett annat sätt att motivera det här problemet är att vi har en graf som är för stor för att lagra i minnet på en enda dator, så vi vill använda två datorer och låta var och en av dem lagra hälften. Så länge vad vi vill räkna ut bara handlar om noder på en av de två datorerna kan vi räkna lokalt -- men om vi vill räkna ut något som involverar kanter mellan de två maskinerna måste de kommunicera med varandra, vilket är långsamt.
  
  För att kunna göra snabba beräkningar vill vi alltså hitta ett sätt att dela upp vår graf så att det inte går så många kanter mellan de två delarna. Det här är ett problem som behöver lösas i praktiken, även om man ofta då har fler än två datorer och behöver hitta en minimal $k$-partition av grafen istället.}

\begin{definition}
  Givet en graf $G = (V, E)$ på $2n$ noder är \texttt{min-bisection} problemet att hitta en minimal bisektion av $G$, alltså att hitta en delmängd $A \in \binom{V}{n}$ som minimerar antalet kanter mellan $A$ och $A^c$. Formellt skriver vi
  $$\min_{A \in \binom{V}{n}} \abs{E(A, A^c)}$$
  där $E(A, A^c)$ alltså är mängden av kanter mellan $A$ och dess komplement $A^c$.
\end{definition}

Hur väl kan vi lösa det här problemet? Ibland är det väldigt svårt -- om vi har fyra personer där alla känner alla, alltså grafen är den fullständiga grafen $K_4$, kommer vi alltid att ha $4$ av $6$ kanter mellan de två delarna.

\begin{figure}
  \centering
  \includegraphics[width=0.5\textwidth]{graphics/K4_min_bisection.png}
  \caption{$K_4$ uppdelad i en bisektion. På grund av symmetrin i grafen är detta så klart enda sättet att dela upp den.}
\end{figure}

Det visar sig att nyckelegenskapen för att kunna göra det här väl är att grafen inte får ha för många kanter relativt antalet noder -- vilket väl inte är allt för överraskande, om man tänker efter.

För att kunna ge en precis variant av det påståendet behöver vi en definition och en sats från grafteorin.

\begin{definition}
  En Hamiltoncykel i en graf är en cykel som innehåller alla noder exakt en gång. Givet $G = ([n],E)$ kan vi alltså se det som en permutation $\sigma \in S_n$ sådan att $\{\sigma(i),\sigma(i+1)\}$ är en kant för alla $i$, och $\{\sigma(1), \sigma(n)\} \in E$.
\end{definition}

\begin{theorem}[Diracs sats]\sidenote[][]{Inte fysikern, en annan Dirac.}
  Om varje nod i $G = ([n], E)$ har grad\sidenote[][]{Antal grannar.} minst $\frac{n}{2}$ så finns det en Hamiltoncykel i $G$.

  \begin{proof}
    Hade gärna inkluderat ett, men vi har inte riktigt tid med det -- och hittade inget probabilistiskt bevis för detta, så det passar inte helt.
  \end{proof}
\end{theorem}

Vi kan använda denna sats för att bevisa följande resultat:

\begin{proposition}
  Låt $G = ([n], E)$ vara en graf på ett jämnt antal noder, och antag att varje nod har grad högst $\frac{n}{2}$. Då existerar det en delmängd $A \in \binom{[n]}{n/2}$ sådan att
  $$E(A, A^c) \leq \frac{\abs{E}}{2}.$$ 

  \begin{proof}
    Låt $G'$ vara komplementgrafen till $G$ -- alltså grafen där det finns en kant mellan varje par av noder som \emph{inte} har en kant mellan sig i $G$, och som inte har en kant mellan par av noder som har en kant i $G$.

    Vi ser enkelt att graden av $i$ i $G'$ är precis $n$ minus graden av $i$ i $G$, så eftersom $d_i \leq n/2$ i $G$ måste $d_i' \geq n/2$ i $G'$. Alltså kan vi tillämpa Diracs sats och hitta en Hamiltoncykel $\sigma$ i komplementgrafen $G'$.

    Vi kan nu använda denna Hamiltoncykel för att para ihop noder i $G$ -- vi matchar $\sigma(1)$ med $\sigma(2)$, $\sigma(3)$ med $\sigma(4)$, och så vidare. Eftersom detta var en Hamiltoncykel i komplementgrafen är vi alltså garanterade att vi aldrig parar ihop två noder som har en kant mellan sig.

    Vi kan nu skapa oss en slumpmässig delmängd $A \in \binom{[n]}{n/2}$ genom att, för varje par, slumpmässigt välja en av de två noderna att ha med i $A$, och låta den andra vara utanför $A$. Denna delmängd kommer ha rätt storlek eftersom vi väljer en nod ur varje par, så vi måste få precis hälften av noderna.

    Låt oss nu räkna ut väntevärdet av $E(A, A^c)$. Vi får att
    \begin{align*}
      \E{E(A, A^c)} &= \E{\sum_{e \in E} \ind{e \in E(A, A^c)}}\\
      &= \sum_{e \in E} \E{\ind{e \in E(A, A^c)}}\\
      &= \sum_{e \in E} \Prob{e \in E(A, A^c)}.
    \end{align*}

    Vad är sannolikheten att en viss fix kant $e = \{u, v\}$ går mellan $A$ och $A^c$? Jo, det händer precis när vi valt att $u \in A$ och $v \in A^c$, eller vice versa. Så vi kan räkna att\sidenote[][]{Vi utnyttjar att de är disjunkta händelser för att gå från $\Prob{(u \in A, v \in A^c) \cup (u \in A^c, v \in A)}$ till summan av de två sannolikheterna.}
    $$\Prob{\{u,v\} \in E(A, A^c)} = \Prob{u \in A, v \in A^c} + \Prob{u \in A^c, v \in A}.$$
    
    Nyckeln nu, och anledningen att vi krånglade med Hamiltoncykeln och hopparningen, är att händelserna $u\in A$ och $v\in A^c$ måste vara oberoende. Om $u$ är i $A$ eller inte beror på en myntsingling vi gjorde för $u$ och noden den parades ihop med -- så om vi kallar dess partner för $w$ så är $u \in A$ och $w \in A$ inte oberoende, men för alla $v \neq w$ är $u \in A$ oberoende från $v \in A$.

    Så hur vet vi att vårt par $u, v$ i vår räkning inte råkar vara hopparade, så att det inte är oberoende ifall de ligger i $A$ eller ej? Jo, vi vet ju att det går en kant mellan $u$ och $v$ -- det är därför vi är intresserade av dem -- men det går ingen kant mellan något par av hopparade noder.

    Alltså kan vi fortsätta vår räkning och få
    \begin{align*}
      \Prob{\{u,v\} \in E(A, A^c)} &= \Prob{u \in A, v \in A^c} + \Prob{u \in A^c, v \in A}\\
      &= \Prob{u \in A}\Prob{v \in A^c} + \Prob{u \in A^c}\Prob{v \in A}\\
      &= \frac{1}{2}\cdot\frac{1}{2} + \frac{1}{2}\cdot\frac{1}{2} = \frac{1}{2}
    \end{align*}
    och alltså har vi att
    \begin{align*}
      \E{E(A,A^c)} &= \sum_{e \in E} \Prob{e \in E(A, A^c)}\\
      &= \sum_{e \in E} \frac{1}{2} = \frac{\abs{E}}{2}.
    \end{align*}

    Enligt vårt sedvanliga argument att väntevärdet omöjligen kan vara mindre än varje specifikt utfall måste det alltså finnas ett specifikt $A$ sådant att $E(A, A^c) \leq \E{E(A,A^c)} = \frac{\abs{E}}{2}$ och vi har bevisat satsen.
  \end{proof}
\end{proposition}

\section{ACNSL-olikheten och VLSI}

I nästan varje sak vi gjort som involverat grafer så har vi ritat bilder av grafen på tavlan, och försökt göra dessa bilder så tydliga som möjligt. Vi väljer att rita dem så att kanterna inte korsar varandra om de inte absolut måste.

Detta leder oss till en faktisk matematisk fråga: Givet en graf $G$, hur få korsningar mellan kanter kan vi rita den med?

\begin{definition}
  En graf $G$ som vi kan rita helt utan att några kanter korsar varandra kallas för \emph{planär}. I allmänhet betecknar vi det minimala antalet korsningar av kanter i en ritning av $G$ med $cr(G)$.\sidenote[][]{Från engelskans \emph{crossing number}.}
\end{definition}

Låt oss återigen ge ett lemma som vi inte bevisar.

\begin{lemma}\label{newtons_formula_lemma}
  Det gäller för alla grafer $G = (V, E)$ att
  $$cr(G) \geq \abs{E} - 3\abs{V} + 6.$$

  \begin{proof}
    Utelämnas.\sidenote[][]{Idén i beviset är att använda Eulers formel och sedan resonera om att ta bort kanter som korsar andra kanter:
    \begin{lemma}[Eulers formel]
      Om $G = (V, E)$ är planär är
      $$3\abs{V} - 6 \geq \abs{E}.$$
    \end{lemma}
    
    Hur bevisar man Eulers formel? Den är ett specialfall av Eulerkarakteristiken av en polyeder. För en väldigt lång och intressant diskussion av just hur man bevisar detta, och primärt vad det faktiskt innebär att bevisa något, se Imre Lakatos bok \emph{Proofs and Refutations}, som handlar enbart om just det.}
  \end{proof}
\end{lemma}

Anledningen att vi ger den här olikheten är att vi faktiskt kan enkelt härleda en starkare version av samma olikhet med ett probabilistiskt trick. Såsom mycket annan modern matematik är listan av upptäckare lång -- till skillnad från förr i tiden görs merparten av all matematik i samarbeten numera.

\begin{theorem}[Ajtai-Chvatal-Newborn-Szemerédi-Leighton (ACNSL)]
  För varje graf $G = (V,E)$ gäller det att, om $\abs{E} \geq 4\abs{V}$ så är
  $$cr(G) \geq \frac{\abs{E}^3}{64\abs{V}^2}.$$

  \begin{proof}
    För att förenkla vår notation, låt $n = \abs{V}$ och $e = \abs{E}$. Tag ett godtyckligt $p \in (0,1)$.

    Vad vi vill göra är att studera en slumpmässig delgraf $H$ till $G$, som ges av att varje nod i $G$ är med i $H$ med sannolikhet $p$, och varje kant är med om bägge dess ändpunkter är med i $H$.\sidenote[][]{Detta kallas i allmänhet \emph{nodperkolation} på $G$. Perkolationsteori är ett stort ämne i sannolikhetsteorin, med kopplingar till fysiken -- man brukar tänka sig det som en modell för hur vatten sipprar genom sten. Således namnlikheten till perkolatorkaffe.}

    Vi får av Lemma \ref{newtons_formula_lemma} att
    $$cr(H) \geq \abs{E(H)} - 3\abs{V(H)} + 6.$$
    Eftersom denna likhet gäller för \emph{alla} utfall måste den också gälla om vi tar väntevärdet på bägge sidorna,\sidenote[][]{
      Vi kan formulera detta som ett lemma:
      \begin{lemma}
        Om $X(\omega) \geq Y(\omega)$ för varje $\omega \in \Omega$ så är $\E{X} \geq \E{Y}$.

        \begin{proof}
          Vi räknar att
          \begin{align*}
            \E{X} &= \sum_{\omega \in \Omega} X(\omega)\mu(\omega)\\
            &\geq \sum_{\omega \in \Omega} Y(\omega)\mu(\omega) = \E{Y}.
          \end{align*}
        \end{proof}
      \end{lemma}
    } så från väntevärdets linjäritet får vi alltså att
    \begin{equation}\label{eq:H_expectations_ineq}
      \E{cr(H)} \geq \E{\abs{E(H)}} - 3\E{\abs{V(H)}} + 6.
    \end{equation}

    Så låt oss studera vardera av dessa väntevärden. Så vi räknar att
    \begin{align*}
      \E{\abs{V(H)}} &= \E{\sum_{v \in V(G)} \ind{v \in V(H)}}\\
      &= \sum_{v \in V(G)} \Prob{v \in V(H)} = \abs{V(G)}p = np,
    \end{align*}
    och
    \begin{align*}
      \E{\abs{E(H)}} &= \E{\sum_{\{u,v\} \in E(G)} \ind{\{u,v\} \in E(H)}}\\
      &= \sum_{\{u,v\}\in E(G)} \Prob{\{u,v\} \in E(H)}\\
      &= \sum_{\{u,v\}\in E(G)} \Prob{u \in V(H), v \in V(H)}\\
      &= \sum_{\{u,v\}\in E(G)} \Prob{u \in V(H)}\Prob{v \in V(H)} = \abs{E(G)}p^2 = ep^2.
    \end{align*}

    Hur hanterar vi $\E{cr(H)}$? Jo, vi tar en ritning av $G$ som har precis $cr(G)$ korsningar, och räknar hur många av de korsningarna som är kvar när vi suddat ut alla noder och kanter utanför $H$.

    För att korsningen skall vara kvar krävs det så klart att bägge kanterna i korsningen är kvar -- och vi har sett att sannolikheten att en enda kant är kvar är $p^2$, så eftersom kanter är kvar oberoende av varandra\sidenote[][]{Förutom om de utgår från samma nod -- men vi kan aldrig tvingas att rita två kanter som utgår från samma nod så att de korsas. (Detta är ganska uppenbart men inte helt trivialt -- fundera ett ögonblick på varför det är sant.)} är sannolikheten att en korsning blir kvar $p^4$.

    Så enligt samma logik som i de andra fallen får vi att $\E{cr(H)} = cr(G)p^4$, så om vi sätter in resultatet av våra räkningar i \eqref{eq:H_expectations_ineq} så får vi att
    $$p^3cr(G) \geq p^2e - 3pn + 6$$
    så om vi nu väljer $p = \frac{4n}{e}$ så får vi alltså
    $$\left(\frac{4n}{e}\right)^3cr(G) \geq \frac{(4n)^2}{e} - 3\frac{4n^2}{e} + 6 > \frac{(4n)^2}{e} - 3\frac{4n^2}{e}$$
    vilket förenklar till påståendet vi sade vi skulle bevisa.
  \end{proof}
\end{theorem}

Varför är det här ett intressant problem? Att rita grafer med så få korsningar som möjligt är inte bara ett estetiskt problem när man ritar saker på en blackboard, utan också ett praktiskt problem när man skall designa kretskort.

Kretskorten har nämligen många olika komponenter, som vi kan tänka oss som noder, som skall kopplas ihop med varandra. Så länge inte kopplingarna korsar varandra kan man helt enkelt måla dit dem, men om de skall korsa behöver man göra något mer komplicerat. Alltså är det av praktiskt intresse att hitta sätt att rita grafer som minimerar antalet korsningar -- problemet i allmänhet med kretskortsdesign kallas för VLSI (Very Large Scale Integration).

\section{Oberoende mängder i triangelfria grafer}

\section{Längsta ökande delföljden i en permutation}

\section{Övningar}


%\bibliography{references}
%\bibliographystyle{plainnat}

\end{document}
